{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Intro\n","\n","Este codigo es parte del proceso de etiquetado.\n","\n","Es la primera parte, donde se elige un modelo de MMsegmentation, se infieren varias imagenes, y con los resultados (una imagen segementada en X clases) se remapea para que la imagen tenga nuestras clases deseadas, consiguiendo así una primera instancia de etiquetas.\n","\n","En este caso se uso el modelo ´san-vit-l14_coco-stuff164k-640x640.py´ y su checkpoint correspondiente https://download.openmmlab.com/mmsegmentation/v0.5/san/san-vit-l14_20230907-a11e098f.pth\n","\n","Este modelo contaba con 172 clases que fueron reasignadas a nuestras 5."],"metadata":{"id":"L1xgM5pNm2K7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UotsUgJS6cOd","outputId":"db12d06b-197a-45d8-a859-e203b8bd4a05"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmsegmentation\n"]}],"source":["import os\n","\n","!pip uninstall -y torch torchvision torchaudio numpy mmcv mmcv-full > /dev/null 2>&1\n","!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118 > /dev/null 2>&1\n","!pip3 install ftfy > /dev/null 2>&1\n","!pip3 install openmim > /dev/null 2>&1\n","!mim install mmengine > /dev/null 2>&1\n","!mim install \"mmcv==2.1.0\" > /dev/null 2>&1\n","\n","!git clone https://github.com/open-mmlab/mmsegmentation.git > /dev/null 2>&1\n","%cd mmsegmentation\n","!git checkout main > /dev/null 2>&1\n","!pip install -e . > /dev/null 2>&1\n","\n","!pip install numpy==1.23.5 --force-reinstall > /dev/null 2>&1\n","\n","os.kill(os.getpid(), 9)"]},{"cell_type":"markdown","source":["Importante montar el drive y tener las images a inferir allí."],"metadata":{"id":"ztMiKTDkoSaO"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgiM8wVhJqb3","executionInfo":{"status":"ok","timestamp":1748138529323,"user_tz":180,"elapsed":30585,"user":{"displayName":"Agustin Gamio","userId":"01963418471080328475"}},"outputId":"9309b32d-b30a-4439-85c3-578a4cff1194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Definicion de Funciones y de remapeo.\n"],"metadata":{"id":"-wDiHpWIoKm4"}},{"cell_type":"code","source":["classes = [\n","    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n","    'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n","    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n","    'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n","    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n","    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n","    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n","    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n","    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n","    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n","    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n","    'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n","    'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'banner',\n","    'blanket', 'branch', 'bridge', 'building-other', 'bush', 'cabinet',\n","    'cage', 'cardboard', 'carpet', 'ceiling-other', 'ceiling-tile',\n","    'cloth', 'clothes', 'clouds', 'counter', 'cupboard', 'curtain',\n","    'desk-stuff', 'dirt', 'door-stuff', 'fence', 'floor-marble',\n","    'floor-other', 'floor-stone', 'floor-tile', 'floor-wood', 'flower',\n","    'fog', 'food-other', 'fruit', 'furniture-other', 'grass', 'gravel',\n","    'ground-other', 'hill', 'house', 'leaves', 'light', 'mat', 'metal',\n","    'mirror-stuff', 'moss', 'mountain', 'mud', 'napkin', 'net', 'paper',\n","    'pavement', 'pillow', 'plant-other', 'plastic', 'platform',\n","    'playingfield', 'railing', 'railroad', 'river', 'road', 'rock', 'roof',\n","    'rug', 'salad', 'sand', 'sea', 'shelf', 'sky-other', 'skyscraper',\n","    'snow', 'solid-other', 'stairs', 'stone', 'straw', 'structural-other',\n","    'table', 'tent', 'textile-other', 'towel', 'tree', 'vegetable',\n","    'wall-brick', 'wall-concrete', 'wall-other', 'wall-panel',\n","    'wall-stone', 'wall-tile', 'wall-wood', 'water-other', 'waterdrops',\n","    'window-blind', 'window-other', 'wood'\n","]\n","\n","# Mapping function\n","def remap_classes(classes):\n","    remapped = {}\n","    for idx, cls in enumerate(classes):\n","        if cls in ['road', 'dirt', 'grass', 'pavement', 'floor-marble', 'floor-other', 'floor-stone', 'floor-tile', 'floor-wood']:\n","            remapped[idx] = 0  # road\n","        elif cls in ['tree', 'apple', 'bush', 'flower', 'leaves', 'moss', 'vegetable', 'plant-other']:\n","            remapped[idx] = 1  # vegetation\n","        elif cls in ['sky-other', 'clouds', 'fog', 'hill']:\n","            remapped[idx] = 2  # sky\n","        elif cls in ['mud', 'person', 'rock', 'building-other', 'furniture-other', 'wall-other',\n","                     'fence', 'gravel', 'net', 'river', 'sand', 'sea', 'stone', 'wood']:\n","            remapped[idx] = 3  # obstacle\n","        else:\n","            remapped[idx] = 4  # other\n","    return remapped\n","\n","def remap_segmentation_mask(predictions, remapped_classes):\n","    # Create a new array with the same shape as the predictions\n","    remapped_mask = np.zeros_like(predictions, dtype=np.uint8)\n","\n","    # Iterate through the mapping and remap the indices\n","    for original_idx, new_idx in remapped_classes.items():\n","        remapped_mask[predictions == original_idx] = new_idx\n","\n","    return remapped_mask\n","\n","def save_segmentation_mask(seg_mask, original_img_path, output_dir):\n","    # Ensure output directory exists\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Convert mask to uint8 grayscale if not already\n","    seg_mask = seg_mask.astype(np.uint8)\n","\n","    # Get image name without extension\n","    base_name = os.path.splitext(os.path.basename(original_img_path))[0]\n","\n","    # Define output path\n","    save_path = os.path.join(output_dir, f\"{base_name}.png\")\n","\n","    # Save the mask (grayscale)\n","    cv2.imwrite(save_path, seg_mask)\n","\n","def visualize_and_save_segmentation(img_path, seg_mask, output_dir=None, alpha=0.5):\n","    from IPython import display\n","\n","    # Load original image\n","    img = mmcv.imread(img_path, channel_order='rgb')\n","    seg_mask = seg_mask.astype(np.uint8)\n","    img = mmcv.imresize(img, (seg_mask.shape[1], seg_mask.shape[0]))\n","\n","    # Define your custom color palette and class names\n","    color_palette = {\n","        0: ((128, 64, 128), 'road'),\n","        1: ((0, 128, 0), 'vegetation'),\n","        2: ((70, 130, 180), 'sky'),\n","        3: ((220, 20, 60), 'obstacle'),\n","        4: ((128, 128, 128), 'other')\n","    }\n","\n","    # Create a blank color mask\n","    color_mask = np.zeros((seg_mask.shape[0], seg_mask.shape[1], 3), dtype=np.uint8)\n","\n","    for class_id, (color, _) in color_palette.items():\n","        color_mask[seg_mask == class_id] = color\n","\n","    # Blend original image with color mask\n","    blended = cv2.addWeighted(img, 1 - alpha, color_mask, alpha, 0)\n","\n","    # Add class labels\n","    for class_id, (color, label) in color_palette.items():\n","        mask = (seg_mask == class_id).astype(np.uint8)\n","        if np.any(mask):\n","            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            if contours:\n","                largest_contour = max(contours, key=cv2.contourArea)\n","                M = cv2.moments(largest_contour)\n","                if M[\"m00\"] > 0:\n","                    cx = int(M[\"m10\"] / M[\"m00\"])\n","                    cy = int(M[\"m01\"] / M[\"m00\"])\n","                    cv2.putText(blended, label, (cx, cy), cv2.FONT_HERSHEY_SIMPLEX,\n","                                0.7, (255, 255, 255), 2, cv2.LINE_AA)\n","\n","    # Display the image\n","    plt.imshow(blended)\n","    plt.axis('off')\n","    plt.show()\n","    plt.pause(0.5)\n","    plt.clf()\n","    display.clear_output(wait=True)\n","\n","    # Save the image if output_dir is provided\n","    if output_dir:\n","        os.makedirs(output_dir, exist_ok=True)\n","        base_name = os.path.splitext(os.path.basename(img_path))[0]\n","        save_path = os.path.join(output_dir, f\"{base_name}_vis.png\")\n","        cv2.imwrite(save_path, cv2.cvtColor(blended, cv2.COLOR_RGB2BGR))  # Convert to BGR for OpenCV saving"],"metadata":{"id":"sMKNjk606nR5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/Facultad/Onceavo semestre/TSCF/Imgs/RobotInTheMud/RobotInTheMud\" /content\n","#!unzip /content/RobotInTheMud.zip -d /content"],"metadata":{"id":"-Cudj9ocJ7TR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmseg.apis import inference_model, init_model\n","from mmseg.utils import register_all_modules\n","import mmcv\n","import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","imgDir = '/content/RobotInTheMud' # Imagenes a generar etiquetas\n","output_mask_dir = \"/content/segmentation_outputs\" # Donde guardar etiquetas\n","output_vis_dir = \"/content/visualizations\" # Donde guardar visualizacion para poder ver resultado.\n","\n","remapped_classes = remap_classes(classes)\n","\n","model = init_model(\n","    config='/content/mmsegmentation/configs/san/san-vit-l14_coco-stuff164k-640x640.py',\n","    checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/san/san-vit-l14_20230907-a11e098f.pth',\n","    device='cuda:0'\n",")\n","\n","img_files = [os.path.join(imgDir, f) for f in os.listdir(imgDir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# Inference loop\n","for img_path in img_files:\n","    result = inference_model(model, img_path)\n","    pred_mask = result.pred_sem_seg.data.squeeze().cpu().numpy()\n","    remapped_mask = remap_segmentation_mask(pred_mask, remapped_classes)\n","    save_segmentation_mask(remapped_mask, img_path, output_mask_dir)\n","    visualize_and_save_segmentation(img_path, remapped_mask, output_vis_dir)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"2mxrem_N8mTT","executionInfo":{"status":"ok","timestamp":1748138694767,"user_tz":180,"elapsed":134448,"user":{"displayName":"Agustin Gamio","userId":"01963418471080328475"}},"outputId":"c8e9ee38-8055-4535-9ea4-53957232edf3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Las imagenes se generan en el colab, si las quiero descargar, copiarlas a mi drive y descargarlas.\n"],"metadata":{"id":"TMhntldMo0_U"}},{"cell_type":"code","source":["!cp -r /content/segmentation_outputs \"/content/drive/MyDrive/Facultad/Onceavo semestre/TSCF/Temp/24 5 2025\""],"metadata":{"id":"6d27b7SVJ4Ww"},"execution_count":null,"outputs":[]}]}