## Introduction

# Toolbox MMSegmentation
## ‚öôÔ∏è Pasos de instalaci√≥n

### ‚ö†Ô∏è Nota

Estos pasos fueron los utilizados para instalar la toolbox **MMSegmentation** en el siguiente entorno.  
Ante cualquier duda o incompatibilidad, se recomienda revisar la gu√≠a oficial de instalaci√≥n de MMSegmentation:

üëâ https://mmsegmentation.readthedocs.io/en/latest/get_started.html

---

### üñ•Ô∏è Entorno utilizado

- **Sistema operativo:** Windows 10/11 usando **WSL 2.0**
- **Distribuci√≥n:** Ubuntu en WSL
- **GPU:** NVIDIA GeForce RTX 3060
- **CUDA Toolkit:** 11.5 (descargar aqu√≠: https://developer.nvidia.com/cuda-11-5-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local)

---

### üîç Verificaci√≥n de GPU

Antes de instalar, verificar que WSL puede acceder a la GPU correctamente:

```bash
nvidia-smi
```

---

### üêç Instalaci√≥n de Conda

Instalar Miniconda o Anaconda desde la documentaci√≥n oficial:  
https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html

---

### üß™ Crear y activar un entorno Conda

```bash
conda create --name MAgro python=3.11 -y
conda activate MAgro
```

---

### üîß Instalaci√≥n de PyTorch y dependencias principales

```bash
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
pip install -U openmim
mim install mmengine
mim install "mmcv==2.1.0"
```

---

### üì¶ Clonar el repositorio y configurar el entorno

```bash
git clone git@github.com:santipais/MAgro.git
cd MAgro
pip install -v -e .
```

---

### ‚úÖ Instalaci√≥n de dependencias adicionales

Estas ya deberian estar instaladas, pero por las dudas:

```bash
pip install ftfy scipy regex
```

‚ö†Ô∏è **Importante**: Es posible que algunas versiones de dependencias fallen si no se fuerza la instalaci√≥n de `numpy`.

```bash
pip install numpy==1.25 --force-reinstall
```

---

### üöÄ Probar que todo funciona

Descargar checpoint y pegarlo en `checkpoints/`.

Correr:

```bash
python inference.py
```

---

## üèãÔ∏è‚Äç‚ôÇÔ∏è Entrenamiento del modelo

### ‚ö†Ô∏è Nota previa

Antes de comenzar, si ocurre alg√∫n error relacionado al path de los m√≥dulos, ejecutar:

```bash
export PYTHONPATH=$(pwd):$PYTHONPATH
```

Y acordate de estar en el entorno de conda que instalamos!

---

### üìÅ Preparar los datos

1. Descargar las im√°genes y etiquetas correspondientes.
2. Colocar:
   - Las im√°genes en: `data/images`
   - Las etiquetas en: `data/labels`

3. Ejecutar el siguiente comando para dividir el dataset:

```bash
python tools/dataset_converters/magro.py --test <porcentaje_test> --val <porcentaje_val> --seed <semilla>
```

Por ejemplo:

```bash
python tools/dataset_converters/magro.py --test 0.1 --val 0.2 --seed 42
```

Por default se tiene un valor de test 0.2, val 0.15 (por lo que, 0.65 de train) y semilla 42.

Esto generar√° las carpetas:

```
data/MAgro/images/
data/MAgro/annotatios/
```

Cada una con sus correspondientes subcarpetas 
```
train/
val/
test/
```

---

### üì• Descargar checkpoint preentrenado

1. Descargar el checkpoint deseado del cual partir para realizar el fine-tuning (por ejemplo, un modelo `SegFormer`). M√°s adelante comentaremos algunos checkpoints obtenidos y de los cual se recomendamos partir.
2. Guardarlo en el directorio que prefieras.

‚ö†Ô∏è Muy importante: editar el archivo `configs/MAgro/segformer_mit-b5_MAgro.py`  
Ir a la **l√≠nea 30** y reemplazar la ruta del checkpoint con la ruta local donde lo guardaste.

---

### üöÄ Entrenar el modelo

Ejecutar el siguiente comando:

```bash
python tools/train.py configs/MAgro/segformer_mit-b5_MAgro.py
```

El entrenamiento creara el archivo `work_dirs/segformer_mit-b5_MAgro/` donde se almacenara todos los pesos y logs.

---

### ‚ÑπÔ∏è Detalles adicionales

El archivo de configuraci√≥n `configs/MAgro/segformer_mit-b5_MAgro.py` est√° configurado para:

- Entrenar durante **40,000 iteraciones**
- Guardar los pesos del modelo cada **5,000 iteraciones**

Estos valores se pueden modificar dentro del mismo archivo de configuraci√≥n seg√∫n tus necesidades.

---

## üëÄ Inferencia y Test del modelo.

## üß™ Test

Para testear el modelo con un peso obtenido, simplemente ejecutar:

```bash
python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE}
```
Donde CONFIG_FILE probablemente ser√° `configs/MAgro/segformer_mit-b5_MAgro.py` y CHEKPOINT_FILE ser√° del estilo `work_dirs/segformer_mit-b5_MAgro/iter_5000.pth`

## Inferencia

Se crearon dos archivos, `inference.py` y `inference_dir.py` para inferar una imagen individual o un directorio de images respectivamente. En ambos casos se va a tener que modificar los archivos para utilizar el archivo config del modelo deseado, los pesos deseados y donde se quieren guardar los resultados. Las lineas a modificar para esto estan marcadas con un comment `# Modificar` al final

---

# üè∑Ô∏è Proceso de etiquetado

## 1. Creaci√≥n del entorno para etiquetar

El proceso de etiquetado se realiz√≥ fuera de WSL, directamente en Windows, creando un nuevo entorno virtual `conda` y luego instalando la herramienta [Labelme](https://github.com/wkentaro/labelme):

```bash
conda create --name etiquetado python=3.11 -y
conda activate etiquetado
pip install labelme
```

---

## 2. Asistencia por notebooks

Durante el desarrollo, se utilizaron dos notebooks de Google Colab:

- **Primer notebook:** Se convierte las m√°scaras de los resultados de inferir con el modelo `san-vit-l14_coco-stuff164k-640x640` , a las 5 clases deseadas por nosotros.
- **Segundo notebook:** convert√≠a esas m√°scaras grises a formato `JSON` con pol√≠gonos, compatibles con `Labelme`.
- **Tercer notebook:** una vez finalizado el proceso de etiquetado con `Labelme`, se utiliz√≥ otro notebook para convertir las anotaciones en formato de pol√≠gonos (`JSON`) al formato compatible con MMSegmentation (m√°scaras en escala de grises).

---

## 3. Edici√≥n final con Labelme

Una vez obtenidas las predicciones en formato `JSON` por el segundo notebook, se realizaron ajustes y retoques manuales ejecutando Labelme con el siguiente comando:

```bash
labelme {directorio_imagenes} --output {directorio_de_etiquetas}
```

Esto permiti√≥ generar las anotaciones finales en formato `Labelme`, que luego al pasar por el tecer notebook, se tienen las etiquetas listas para ser utilizadas por la toolbox MMSegmentation.

---

# üìñ Citaci√≥n

Este proyecto usa [MMSegmentation](https://github.com/open-mmlab/mmsegmentation). Si lo usas, para citarlo:

```bibtex
@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}
