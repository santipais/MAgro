## Introduction
## âš™ï¸ Pasos de instalaciÃ³n

### âš ï¸ Nota

Estos pasos fueron los utilizados para instalar la toolbox **MMSegmentation** en el siguiente entorno.  
Ante cualquier duda o incompatibilidad, se recomienda revisar la guÃ­a oficial de instalaciÃ³n de MMSegmentation:

ğŸ‘‰ https://mmsegmentation.readthedocs.io/en/latest/get_started.html

---

### ğŸ–¥ï¸ Entorno utilizado

- **Sistema operativo:** Windows 10/11 usando **WSL 2.0**
- **DistribuciÃ³n:** Ubuntu en WSL
- **GPU:** NVIDIA GeForce RTX 3060
- **CUDA Toolkit:** 11.5 (descargar aquÃ­: https://developer.nvidia.com/cuda-11-5-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local)

---

### ğŸ” VerificaciÃ³n de GPU

Antes de instalar, verificar que WSL puede acceder a la GPU correctamente:

```bash
nvidia-smi
```

---

### ğŸ InstalaciÃ³n de Conda

Instalar Miniconda o Anaconda desde la documentaciÃ³n oficial:  
https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html

---

### ğŸ§ª Crear y activar un entorno Conda

```bash
conda create --name MAgro python=3.11 -y
conda activate MAgro
```

---

### ğŸ”§ InstalaciÃ³n de PyTorch y dependencias principales

```bash
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
pip install -U openmim
mim install mmengine
mim install "mmcv==2.1.0"
```

---

### ğŸ“¦ Clonar el repositorio y configurar el entorno

```bash
git clone <URL-de-nuestro-repositorio>
cd <nombre-del-repo>
pip install -v -e .
```

---

### âœ… InstalaciÃ³n de dependencias adicionales

Estas ya deberian estar instaladas, pero por las dudas:

```bash
pip install ftfy scipy regex
```

âš ï¸ **Importante**: Es posible que algunas versiones de dependencias fallen si no se fuerza la instalaciÃ³n de `numpy`.

```bash
pip install numpy==1.25 --force-reinstall
```

---

### ğŸš€ Probar que todo funciona

```bash
python inference.py
```

---

## ğŸ‹ï¸â€â™‚ï¸ Entrenamiento del modelo

### âš ï¸ Nota previa

Antes de comenzar, si ocurre algÃºn error relacionado al path de los mÃ³dulos, ejecutar:

```bash
export PYTHONPATH=$(pwd):$PYTHONPATH
```

Y acordate de estar en el entorno de conda que instalamos!

---

### ğŸ“ Preparar los datos

1. Descargar las imÃ¡genes y etiquetas correspondientes.
2. Colocar:
   - Las imÃ¡genes en: `data/images`
   - Las etiquetas en: `data/labels`

3. Ejecutar el siguiente comando para dividir el dataset:

```bash
python tools/dataset_converters/magro.py --test <porcentaje_test> --val <porcentaje_val> --seed <semilla>
```

Por ejemplo:

```bash
python tools/dataset_converters/magro.py --test 0.1 --val 0.2 --seed 42
```

Por default se tiene un valor de test 0.2, val 0.15 (por lo que, 0.65 de train) y semilla 42.

Esto generarÃ¡ las carpetas:

```
data/MAgro/images/
data/MAgro/annotatios/
```

Cada una con sus correspondientes subcarpetas 
```
train/
val/
test/
```

---

### ğŸ“¥ Descargar checkpoint preentrenado

1. Descargar el checkpoint deseado del cual partir para realizar el fine-tuning (por ejemplo, un modelo `SegFormer`). MÃ¡s adelante comentaremos algunos checkpoints obtenidos y de los cual se recomendamos partir.
2. Guardarlo en el directorio que prefieras.

âš ï¸ Muy importante: editar el archivo `configs/MAgro/segformer_mit-b5_MAgro.py`  
Ir a la **lÃ­nea 30** y reemplazar la ruta del checkpoint con la ruta local donde lo guardaste.

---

### ğŸš€ Entrenar el modelo

Ejecutar el siguiente comando:

```bash
python tools/train.py configs/MAgro/segformer_mit-b5_MAgro.py
```

El entrenamiento creara el archivo `work_dirs/segformer_mit-b5_MAgro/` donde se almacenara todos los pesos y logs.

---

### â„¹ï¸ Detalles adicionales

El archivo de configuraciÃ³n `configs/MAgro/segformer_mit-b5_MAgro.py` estÃ¡ configurado para:

- Entrenar durante **40,000 iteraciones**
- Guardar los pesos del modelo cada **5,000 iteraciones**

Estos valores se pueden modificar dentro del mismo archivo de configuraciÃ³n segÃºn tus necesidades.

---

## ğŸ‘€ Inferencia y Test del modelo.

## ğŸ§ª Test

Para testear el modelo con un peso obtenido, simplemente ejecutar:

```bash
python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE}
```
Donde CONFIG_FILE probablemente serÃ¡ `configs/MAgro/segformer_mit-b5_MAgro.py` y CHEKPOINT_FILE serÃ¡ del estilo `work_dirs/segformer_mit-b5_MAgro/iter_5000.pth`

## Inferencia

Se crearon dos archivos, `inference.py` y `inference_dir.py` para inferar una imagen individual o un directorio de images respectivamente. En ambos casos se va a tener que modificar los archivos para utilizar el archivo config del modelo deseado, los pesos deseados y donde se quieren guardar los resultados. Las lineas a modificar para esto estan marcadas con un comment `# Modificar` al final


## ğŸ“– CitaciÃ³n

Este proyecto usa [MMSegmentation](https://github.com/open-mmlab/mmsegmentation). Si lo usas, para citarlo:

```bibtex
@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}
